{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Modeling<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Loading-in-dataset\" data-toc-modified-id=\"Loading-in-dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading in dataset</a></span></li><li><span><a href=\"#Assigning-predictor-variable-and-target-variable\" data-toc-modified-id=\"Assigning-predictor-variable-and-target-variable-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Assigning predictor variable and target variable</a></span></li><li><span><a href=\"#Modeling---preprocessing\" data-toc-modified-id=\"Modeling---preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modeling - preprocessing</a></span></li><li><span><a href=\"#Modeling---cross-validation-and-performance-evaluation\" data-toc-modified-id=\"Modeling---cross-validation-and-performance-evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modeling - cross-validation and performance evaluation</a></span></li><li><span><a href=\"#Modeling---final-model\" data-toc-modified-id=\"Modeling---final-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Modeling - final model</a></span></li><li><span><a href=\"#Evaluate-the-model-using-your-test-dataset\" data-toc-modified-id=\"Evaluate-the-model-using-your-test-dataset-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Evaluate the model using your test dataset</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: please load and preprocess your test dataset along with the original (training) dataset until the final model training part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import punkt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Loading in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load in the notebook that contains all extracted features we created for the products\n",
    "product = pd.read_csv('all_features.csv')\n",
    "\n",
    "# load in the original notebook for all products\n",
    "product_original = pd.read_excel('Behold+product+data+04262021.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# appending the brand of each product to the dataframe that has extracted features \n",
    "product['brand'] = product_original['brand']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The final dataframe contains lemmatized description of products (in one column), each of the 30 features that are extracted from the texts, all features combined (in one column), and the brand of each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>lemm_total</th>\n",
       "      <th>detailed_category</th>\n",
       "      <th>general_category</th>\n",
       "      <th>gender</th>\n",
       "      <th>season</th>\n",
       "      <th>class</th>\n",
       "      <th>closure</th>\n",
       "      <th>color</th>\n",
       "      <th>dry_clean_only</th>\n",
       "      <th>...</th>\n",
       "      <th>toe_style</th>\n",
       "      <th>trend</th>\n",
       "      <th>wash</th>\n",
       "      <th>width</th>\n",
       "      <th>location</th>\n",
       "      <th>material_percent</th>\n",
       "      <th>material</th>\n",
       "      <th>brand_specific</th>\n",
       "      <th>all_features</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01EX0PN4J9WRNZH5F93YEX6QAF</td>\n",
       "      <td>unknown khadi stripe shirt our signature shirt...</td>\n",
       "      <td>shirt</td>\n",
       "      <td>top</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spring</td>\n",
       "      <td>shirt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>black white</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>black white</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shirt top  spring shirt  black white         ...</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01F0C4SKZV6YXS3265JMC39NXW</td>\n",
       "      <td>unknown ruffle market dress loopy pink sistine...</td>\n",
       "      <td>dress</td>\n",
       "      <td>onepiece</td>\n",
       "      <td>woman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dress</td>\n",
       "      <td>strap zipper</td>\n",
       "      <td>pink</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>organic</td>\n",
       "      <td>dress onepiece woman  dress strap zipper pink...</td>\n",
       "      <td>Collina Strada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id  \\\n",
       "0  01EX0PN4J9WRNZH5F93YEX6QAF   \n",
       "1  01F0C4SKZV6YXS3265JMC39NXW   \n",
       "\n",
       "                                          lemm_total detailed_category  \\\n",
       "0  unknown khadi stripe shirt our signature shirt...             shirt   \n",
       "1  unknown ruffle market dress loopy pink sistine...             dress   \n",
       "\n",
       "  general_category gender  season  class       closure        color  \\\n",
       "0              top    NaN  spring  shirt           NaN  black white   \n",
       "1         onepiece  woman     NaN  dress  strap zipper         pink   \n",
       "\n",
       "  dry_clean_only  ... toe_style trend         wash width location  \\\n",
       "0            NaN  ...       NaN   NaN  black white   NaN      NaN   \n",
       "1            NaN  ...       NaN   NaN          NaN   NaN       ny   \n",
       "\n",
       "  material_percent material brand_specific  \\\n",
       "0              NaN      NaN            NaN   \n",
       "1              NaN      NaN        organic   \n",
       "\n",
       "                                        all_features           brand  \n",
       "0   shirt top  spring shirt  black white         ...             Two  \n",
       "1   dress onepiece woman  dress strap zipper pink...  Collina Strada  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Assigning predictor variable and target variable\n",
    "\n",
    "- For the predictor variable, we chose to combine all extracted features, and append it with lemmatized product descriptions&details in case there are not many features extracted. In this way, we can make sure that most products' predictor variable will have more than 64 words when we later pad the documents with max length 64. \n",
    "\n",
    "    \n",
    "- For the target variable, we chose to only include the top 30 appearing brands in the dataset as well as an 'other' category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We use 'X' to denote the column that represents the predictor variable we are going to use in the model\n",
    "# It contains all the features of the product, followed by lemmatized description/details \n",
    "\n",
    "product['X'] = product['all_features'] + product['lemm_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We use 'target' to denote the column that represents the target variable of the dataset, which contains a total\n",
    "# of 31 classes \n",
    "\n",
    "top30 = product.brand.value_counts()[:30].index.to_list()\n",
    "def assign_brand(name):\n",
    "    '''Assigns the brand to each record (either the top 30 brands or Other)'''\n",
    "    if name in top30:\n",
    "        return name\n",
    "    else:\n",
    "        return 'Other'\n",
    "product['target'] = product.brand.apply(assign_brand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modeling - preprocessing\n",
    "\n",
    "- Remove stopwords for the texts in the predictor variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/BarbaraLiao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/BarbaraLiao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing nltk stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords') \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "# adding 'unknown' as a stopword\n",
    "english_stopwords.add('unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(title):\n",
    "    '''remove stopwords for a document'''\n",
    "    if isinstance(title, str):\n",
    "        tokens = nltk.word_tokenize(title)\n",
    "        filtered_tokens = []\n",
    "        for token in tokens:\n",
    "            if token in english_stopwords:\n",
    "                continue\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "        return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# removing stopwords for the predictor variable in the data set\n",
    "\n",
    "product[\"X\"] = product[\"X\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modeling - cross-validation and performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# formatting the predictor variable and target variable into 2 separate lists\n",
    "X = product['X'].to_list()\n",
    "Y = product['target'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Tokenize the top 5000 appearing words, and mark the rest as UNKNOWN_TOKEN\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 141, 598, 386, 26]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "def integer_encode_documents(docs, tokenizer):\n",
    "    '''apply the input tokenizer on the input docs and return sequences'''\n",
    "    return tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "# integer encode the documents\n",
    "encoded_docs = integer_encode_documents(X, tokenizer)\n",
    "# see some lengths of the documents\n",
    "list(map(len, encoded_docs))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  95,    7,  189, ...,    0,    0,    0],\n",
       "       [   7,    1,    7, ...,   55,    1,    7],\n",
       "       [2903,  437,  391, ..., 1329,  456,    1],\n",
       "       ...,\n",
       "       [  20,   32,  282, ...,   12, 2589,  279],\n",
       "       [2621,  292,  418, ...,    7, 2621,  292],\n",
       "       [   6,  125,   43, ...,    6,  186, 1120]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set MAX_SEQUENCE_LENGTH to 64\n",
    "MAX_SEQUENCE_LENGTH = 64\n",
    "\n",
    "# This is a list of lists, the numbers represent the index position of each word;\n",
    "# for instance, 33 means the 33rd word in the vocabulary\n",
    "\n",
    "# This step makes sure that each document in the predictor variable has a fixed length of 64 \n",
    "\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This step encodes the 31 brand category to 31 labels, and makes 31 binary columns for them\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "labels = to_categorical(encoder.fit_transform(Y),31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<b> Note: please do not include your test dataset at this point<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# making 5-fold cross validation data sets\n",
    "# for each item in 'cv', it contains 4 lists that represent X_train, X_test,Y_train, and Y_test, respectively\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "cv = []\n",
    "for train_index, test_index in kf.split(padded_docs):\n",
    "    X_train, X_test = padded_docs[train_index], padded_docs[test_index]\n",
    "    Y_train, Y_test = labels[train_index], labels[test_index]\n",
    "    cv += [[X_train, X_test,Y_train, Y_test]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array, argmax, asarray, zeros\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = int(len(tokenizer.word_index) * 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def load_glove_vectors():\n",
    "    '''load in the glove vectors and return embeddings index'''\n",
    "    embeddings_index = {}\n",
    "    with open('glove.6B.100d.txt') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "embeddings_index = load_glove_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = zeros((VOCAB_SIZE, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define lstm model\n",
    "\n",
    "import keras\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM\n",
    "from keras.layers import Flatten, Masking\n",
    "\n",
    "def make_lstm_classification_model(plot=False):\n",
    "    model =  keras.models.Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(LSTM(units=32, input_shape=(1, MAX_SEQUENCE_LENGTH)))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(31, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 64, 100)           3740000   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 64, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 31)                527       \n",
      "=================================================================\n",
      "Total params: 3,758,079\n",
      "Trainable params: 18,079\n",
      "Non-trainable params: 3,740,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the lstm model\n",
    "\n",
    "model = make_lstm_classification_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<b> Note: You can comment out the next 2 cells because it will take extremely long time to run <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 16s 13ms/step - loss: 2.2146 - accuracy: 0.4430 - val_loss: 1.0371 - val_accuracy: 0.7408\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 13s 12ms/step - loss: 0.9002 - accuracy: 0.7741 - val_loss: 0.7116 - val_accuracy: 0.8215\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.6164 - accuracy: 0.8464 - val_loss: 0.5510 - val_accuracy: 0.8610\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.4658 - accuracy: 0.8833 - val_loss: 0.4980 - val_accuracy: 0.8755\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.3859 - accuracy: 0.9031 - val_loss: 0.4388 - val_accuracy: 0.8938\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.3230 - accuracy: 0.9176 - val_loss: 0.4155 - val_accuracy: 0.8982\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.2855 - accuracy: 0.9265 - val_loss: 0.3823 - val_accuracy: 0.9065\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.2552 - accuracy: 0.9358 - val_loss: 0.3837 - val_accuracy: 0.9090\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.2271 - accuracy: 0.9419 - val_loss: 0.3685 - val_accuracy: 0.9133\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.2034 - accuracy: 0.9467 - val_loss: 0.3621 - val_accuracy: 0.9162\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.1918 - accuracy: 0.9527 - val_loss: 0.3617 - val_accuracy: 0.9170\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.1775 - accuracy: 0.9546 - val_loss: 0.3523 - val_accuracy: 0.9187\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 16s 15ms/step - loss: 0.1586 - accuracy: 0.9610 - val_loss: 0.3509 - val_accuracy: 0.9200\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 16s 14ms/step - loss: 0.1405 - accuracy: 0.9633 - val_loss: 0.3704 - val_accuracy: 0.9150\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.1355 - accuracy: 0.9646 - val_loss: 0.3501 - val_accuracy: 0.9220\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.1315 - accuracy: 0.9651 - val_loss: 0.3825 - val_accuracy: 0.9087\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.1223 - accuracy: 0.9680 - val_loss: 0.3633 - val_accuracy: 0.9208\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.1053 - accuracy: 0.9721 - val_loss: 0.3447 - val_accuracy: 0.9260\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.1118 - accuracy: 0.9714 - val_loss: 0.3551 - val_accuracy: 0.9268\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0985 - accuracy: 0.9753 - val_loss: 0.3644 - val_accuracy: 0.9252\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3496 - accuracy: 0.9292\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 15s 14ms/step - loss: 0.1762 - accuracy: 0.9568 - val_loss: 0.3359 - val_accuracy: 0.9283\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.1415 - accuracy: 0.9644 - val_loss: 0.3284 - val_accuracy: 0.9317\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.1255 - accuracy: 0.9675 - val_loss: 0.3395 - val_accuracy: 0.9258\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.1156 - accuracy: 0.9694 - val_loss: 0.3283 - val_accuracy: 0.9308\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.1078 - accuracy: 0.9722 - val_loss: 0.3334 - val_accuracy: 0.9268\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 15s 14ms/step - loss: 0.1008 - accuracy: 0.9728 - val_loss: 0.3695 - val_accuracy: 0.9205\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0940 - accuracy: 0.9740 - val_loss: 0.3479 - val_accuracy: 0.9312\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0892 - accuracy: 0.9759 - val_loss: 0.3597 - val_accuracy: 0.9222\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 16s 14ms/step - loss: 0.0835 - accuracy: 0.9779 - val_loss: 0.3507 - val_accuracy: 0.9310\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0748 - accuracy: 0.9806 - val_loss: 0.3616 - val_accuracy: 0.9335\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0775 - accuracy: 0.9789 - val_loss: 0.4089 - val_accuracy: 0.9205\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0746 - accuracy: 0.9786 - val_loss: 0.4032 - val_accuracy: 0.9210\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0632 - accuracy: 0.9831 - val_loss: 0.4030 - val_accuracy: 0.9277\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0652 - accuracy: 0.9821 - val_loss: 0.4121 - val_accuracy: 0.9268\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0607 - accuracy: 0.9835 - val_loss: 0.4036 - val_accuracy: 0.9293\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0593 - accuracy: 0.9833 - val_loss: 0.4137 - val_accuracy: 0.9265\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 16s 14ms/step - loss: 0.0622 - accuracy: 0.9830 - val_loss: 0.4263 - val_accuracy: 0.9260\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0573 - accuracy: 0.9843 - val_loss: 0.4778 - val_accuracy: 0.9195\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0626 - accuracy: 0.9823 - val_loss: 0.4245 - val_accuracy: 0.9323\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0438 - accuracy: 0.9887 - val_loss: 0.4248 - val_accuracy: 0.9280\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2181 - accuracy: 0.9506\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.1146 - accuracy: 0.9697 - val_loss: 0.3972 - val_accuracy: 0.9300\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0765 - accuracy: 0.9786 - val_loss: 0.3981 - val_accuracy: 0.9335\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0658 - accuracy: 0.9817 - val_loss: 0.4017 - val_accuracy: 0.9340\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0645 - accuracy: 0.9824 - val_loss: 0.3880 - val_accuracy: 0.9310\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0544 - accuracy: 0.9850 - val_loss: 0.4222 - val_accuracy: 0.9252\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0590 - accuracy: 0.9834 - val_loss: 0.4072 - val_accuracy: 0.9345\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0557 - accuracy: 0.9850 - val_loss: 0.4168 - val_accuracy: 0.9295\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0486 - accuracy: 0.9869 - val_loss: 0.4277 - val_accuracy: 0.9317\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0576 - accuracy: 0.9834 - val_loss: 0.4252 - val_accuracy: 0.9270\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0506 - accuracy: 0.9857 - val_loss: 0.4411 - val_accuracy: 0.9298\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0451 - accuracy: 0.9875 - val_loss: 0.4545 - val_accuracy: 0.9260\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0510 - accuracy: 0.9852 - val_loss: 0.4529 - val_accuracy: 0.9270\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0471 - accuracy: 0.9870 - val_loss: 0.4726 - val_accuracy: 0.9298\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 16s 14ms/step - loss: 0.0454 - accuracy: 0.9878 - val_loss: 0.4752 - val_accuracy: 0.9302\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0446 - accuracy: 0.9874 - val_loss: 0.4676 - val_accuracy: 0.9280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0374 - accuracy: 0.9902 - val_loss: 0.5032 - val_accuracy: 0.9270\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0441 - accuracy: 0.9877 - val_loss: 0.4745 - val_accuracy: 0.9295\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0451 - accuracy: 0.9872 - val_loss: 0.4746 - val_accuracy: 0.9237\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0388 - accuracy: 0.9890 - val_loss: 0.4887 - val_accuracy: 0.9285\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0384 - accuracy: 0.9892 - val_loss: 0.5119 - val_accuracy: 0.9227\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1635 - accuracy: 0.9599\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0856 - accuracy: 0.9769 - val_loss: 0.4816 - val_accuracy: 0.9270\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0555 - accuracy: 0.9843 - val_loss: 0.4652 - val_accuracy: 0.9298\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0430 - accuracy: 0.9883 - val_loss: 0.4909 - val_accuracy: 0.9320\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 13s 12ms/step - loss: 0.0450 - accuracy: 0.9874 - val_loss: 0.4774 - val_accuracy: 0.9305\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 13s 12ms/step - loss: 0.0376 - accuracy: 0.9899 - val_loss: 0.4746 - val_accuracy: 0.9342\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0445 - accuracy: 0.9876 - val_loss: 0.4796 - val_accuracy: 0.9285\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0422 - accuracy: 0.9882 - val_loss: 0.4964 - val_accuracy: 0.9305\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0419 - accuracy: 0.9879 - val_loss: 0.5137 - val_accuracy: 0.9317\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0385 - accuracy: 0.9893 - val_loss: 0.4914 - val_accuracy: 0.9310\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0379 - accuracy: 0.9894 - val_loss: 0.4934 - val_accuracy: 0.9327\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 16s 14ms/step - loss: 0.0322 - accuracy: 0.9912 - val_loss: 0.5427 - val_accuracy: 0.9285\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0442 - accuracy: 0.9883 - val_loss: 0.4846 - val_accuracy: 0.9287\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0383 - accuracy: 0.9889 - val_loss: 0.5258 - val_accuracy: 0.9308\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0347 - accuracy: 0.9911 - val_loss: 0.5221 - val_accuracy: 0.9270\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0359 - accuracy: 0.9900 - val_loss: 0.5248 - val_accuracy: 0.9227\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0366 - accuracy: 0.9894 - val_loss: 0.5017 - val_accuracy: 0.9310\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0362 - accuracy: 0.9902 - val_loss: 0.5315 - val_accuracy: 0.9280\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0384 - accuracy: 0.9892 - val_loss: 0.4991 - val_accuracy: 0.9337\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0333 - accuracy: 0.9907 - val_loss: 0.5279 - val_accuracy: 0.9283\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0328 - accuracy: 0.9909 - val_loss: 0.5346 - val_accuracy: 0.9300\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1234 - accuracy: 0.9684\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0610 - accuracy: 0.9836 - val_loss: 0.1157 - val_accuracy: 0.9675\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0411 - accuracy: 0.9887 - val_loss: 0.1067 - val_accuracy: 0.9705\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0298 - accuracy: 0.9920 - val_loss: 0.1068 - val_accuracy: 0.9730\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0340 - accuracy: 0.9906 - val_loss: 0.1222 - val_accuracy: 0.9653\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0373 - accuracy: 0.9891 - val_loss: 0.1040 - val_accuracy: 0.9747\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0351 - accuracy: 0.9904 - val_loss: 0.1108 - val_accuracy: 0.9688\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0370 - accuracy: 0.9895 - val_loss: 0.1018 - val_accuracy: 0.9728\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 16s 14ms/step - loss: 0.0364 - accuracy: 0.9904 - val_loss: 0.1364 - val_accuracy: 0.9657\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0370 - accuracy: 0.9896 - val_loss: 0.1280 - val_accuracy: 0.9668\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 0.1467 - val_accuracy: 0.9632\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0303 - accuracy: 0.9917 - val_loss: 0.1284 - val_accuracy: 0.9675\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0314 - accuracy: 0.9910 - val_loss: 0.1575 - val_accuracy: 0.9620\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 14s 13ms/step - loss: 0.0382 - accuracy: 0.9891 - val_loss: 0.1518 - val_accuracy: 0.9625\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 15s 14ms/step - loss: 0.0340 - accuracy: 0.9901 - val_loss: 0.1462 - val_accuracy: 0.9647\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0277 - accuracy: 0.9924 - val_loss: 0.1582 - val_accuracy: 0.9625\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 16s 14ms/step - loss: 0.0326 - accuracy: 0.9907 - val_loss: 0.1545 - val_accuracy: 0.9640\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 15s 14ms/step - loss: 0.0307 - accuracy: 0.9919 - val_loss: 0.1887 - val_accuracy: 0.9592\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 16s 15ms/step - loss: 0.0306 - accuracy: 0.9918 - val_loss: 0.1628 - val_accuracy: 0.9650\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 15s 13ms/step - loss: 0.0346 - accuracy: 0.9900 - val_loss: 0.1909 - val_accuracy: 0.9588\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 14s 12ms/step - loss: 0.0354 - accuracy: 0.9899 - val_loss: 0.1735 - val_accuracy: 0.9605\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2937 - accuracy: 0.9545\n"
     ]
    }
   ],
   "source": [
    "# evaluating model performance with cv and recording the accuracy in the dictionary 'cv_results'\n",
    "\n",
    "cv_results = {}\n",
    "for i in range(5):\n",
    "\n",
    "    # train the model\n",
    "    history = model.fit(cv[i][0], cv[i][2],validation_split = 0.1, epochs=20, verbose=1)\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(cv[i][1], cv[i][3], verbose=1)\n",
    "    cv_results[i] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9291999936103821,\n",
       " 1: 0.9506000280380249,\n",
       " 2: 0.9599000215530396,\n",
       " 3: 0.9684000015258789,\n",
       " 4: 0.9545000195503235}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modeling - final model\n",
    "- Here we use all the data to train the lstm model so that its performance can be improved\n",
    "\n",
    "- <b> Note: please do not include your test dataset at this point<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 64, 100)           3740000   \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, 64, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 31)                527       \n",
      "=================================================================\n",
      "Total params: 3,758,079\n",
      "Trainable params: 18,079\n",
      "Non-trainable params: 3,740,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1407/1407 [==============================] - 32s 21ms/step - loss: 2.0825 - accuracy: 0.4731 - val_loss: 0.8813 - val_accuracy: 0.7738\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 0.7774 - accuracy: 0.8047 - val_loss: 0.6102 - val_accuracy: 0.8466\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.5143 - accuracy: 0.8691 - val_loss: 0.4986 - val_accuracy: 0.8716\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.3921 - accuracy: 0.9014 - val_loss: 0.4375 - val_accuracy: 0.8884\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.3305 - accuracy: 0.9150 - val_loss: 0.3972 - val_accuracy: 0.8976\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 0.2934 - accuracy: 0.9245 - val_loss: 0.3844 - val_accuracy: 0.9042\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.2517 - accuracy: 0.9365 - val_loss: 0.3613 - val_accuracy: 0.9120\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.2293 - accuracy: 0.9409 - val_loss: 0.3546 - val_accuracy: 0.9156\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.2036 - accuracy: 0.9471 - val_loss: 0.3441 - val_accuracy: 0.9166\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.1881 - accuracy: 0.9500 - val_loss: 0.3329 - val_accuracy: 0.9206\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 0.1733 - accuracy: 0.9554 - val_loss: 0.3297 - val_accuracy: 0.9232\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.1672 - accuracy: 0.9558 - val_loss: 0.3212 - val_accuracy: 0.9246\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.1477 - accuracy: 0.9608 - val_loss: 0.3163 - val_accuracy: 0.9254\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.1406 - accuracy: 0.9633 - val_loss: 0.3050 - val_accuracy: 0.9298\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 0.1304 - accuracy: 0.9651 - val_loss: 0.3215 - val_accuracy: 0.9282\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.1252 - accuracy: 0.9667 - val_loss: 0.3470 - val_accuracy: 0.9228\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.1194 - accuracy: 0.9688 - val_loss: 0.3123 - val_accuracy: 0.9298\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.1057 - accuracy: 0.9719 - val_loss: 0.3176 - val_accuracy: 0.9322\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 0.1000 - accuracy: 0.9738 - val_loss: 0.3203 - val_accuracy: 0.9330\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.0940 - accuracy: 0.9745 - val_loss: 0.3272 - val_accuracy: 0.9340\n"
     ]
    }
   ],
   "source": [
    "model = make_lstm_classification_model()\n",
    "history = model.fit(padded_docs, labels,validation_split = 0.1, epochs=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluate the model using your test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Please replace X_test with your transformed predictor variable\n",
    "# Please replace y_test with your transformed target variable\n",
    "# And run the following code\n",
    "\n",
    "#loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "#print('Accuracy: %f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Modeling",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
